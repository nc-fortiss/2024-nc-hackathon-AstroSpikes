{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Global Akida workflow\n",
    "\n",
    ".. Note:: Please refer to the TensorFlow  [tf.keras.models](https://www.tensorflow.org/api_docs/python/tf/keras/models)_\n",
    "          module for model creation/import details and the [TensorFlow Guide](https://www.tensorflow.org/guide)_ for TensorFlow usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create and train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 18:34:26.783825: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 18:34:27.217428: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-12 18:34:27.217556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-12 18:34:27.282490: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-12 18:34:27.417924: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-12 18:34:27.420170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-12 18:34:29.915768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_mobilnet_v1.py import PoseEstimationLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load and reshape projection dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 7)\n",
      "(120, 240, 240, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#TODO: import the dataset\n",
    "\n",
    "#TODO: Load projection dataset\n",
    "# x_test, y_test = ...\n",
    "\n",
    "# import csv\n",
    "position_dir = './event_frames'\n",
    "# position_file = 'position.csv'\n",
    "# # Load position data from CSV\n",
    "y_train = tf.convert_to_tensor(list(range(7)), dtype=tf.float32)\n",
    "y_train = tf.expand_dims(y_train, axis=1)\n",
    "y_train = tf.tile(y_train, [1, 200])\n",
    "y_train = tf.transpose(y_train, perm=[1, 0])\n",
    "print(y_train.shape)\n",
    "# with open(os.path.abspath(os.path.join(position_dir, position_file))) as file:\n",
    "#     reader = csv.reader(file)\n",
    "#     for row in reader:\n",
    "#         y_test.append(row)\n",
    "        \n",
    "# Load images\n",
    "x_train = []\n",
    "for _ in range(12):\n",
    "    for i in range(10):\n",
    "        img = plt.imread(f'{position_dir}/frame_{i:02}.png',)\n",
    "        x_train.append(img)\n",
    "    \n",
    "    \n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "print(x_train.shape)\n",
    "    \n",
    "\n",
    "\n",
    "# Display a few images from the test set\n",
    "f, axarr = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    pass\n",
    "    #TODO: adjust the following line to display the images\n",
    "    axarr[i].imshow(x_train[i])\n",
    "plt.show()\n",
    "\n",
    "x_train = tf.stack((x_train[:, :, :, 0], x_train[:, :, :, 2]), axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Model definition\n",
    "\n",
    "Note that at this stage, there is nothing specific to the Akida IP.\n",
    "The model constructed below, as inspired by [this example](https://www.tensorflow.org/model_optimization/guide/quantization/training_example#train_a_model_for_mnist_without_quantization_aware_training)_,\n",
    "is a completely standard [Keras](https://www.tensorflow.org/api_docs/python/tf/keras)_ CNN model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DEFINE MODEL\n",
    "base_model = keras.applications.MobileNet(include_top=False, input_shape=(240, 240, 2), weights=None)\n",
    "# base_model.trainable = False  # Freeze all layers in the base model\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "output_l = tf.keras.layers.Dense(7, activation='linear')(x)\n",
    "model_keras = Model(inputs=base_model.input, outputs=output_l)\n",
    "\n",
    "print(model_keras.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Model training\n",
    "\n",
    "Given the model created above, train the model and check its accuracy. The model should achieve\n",
    "a test accuracy over 98% after 10 epochs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 240, 240, 2)\n",
      "(30, 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 12s 12s/step - loss: 14.2744 - accuracy: 0.1852 - val_loss: 12.7162 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 336.0388 - accuracy: 0.5556 - val_loss: 12.7635 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.4256 - accuracy: 0.7778 - val_loss: 12.9752 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 84.1204 - accuracy: 1.0000 - val_loss: 13.0905 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 76.5225 - accuracy: 1.0000 - val_loss: 13.0396 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.5442 - accuracy: 1.0000 - val_loss: 12.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5.8985 - accuracy: 0.7407 - val_loss: 12.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.2416 - accuracy: 0.5556 - val_loss: 12.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.5656 - accuracy: 0.7037 - val_loss: 12.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.1233 - accuracy: 0.7778 - val_loss: 12.4485 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_keras.compile(\n",
    "    loss=keras.losses.MeanSquaredError(), #TODO: define the loss function\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "_ = model_keras.fit(x_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 240, 240, 2)\n",
      "(30, 7)\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "score = model_keras.evaluate(x_train, y_train, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. 8-bit quantization\n",
    "\n",
    "An Akida accelerator processes 8 or 4-bits integer activations and weights. Therefore,\n",
    "the floating point Keras model must be quantized in preparation to run on an Akida accelerator.\n",
    "\n",
    "The QuantizeML [quantize](../../api_reference/quantizeml_apis.html#quantizeml.models.quantize)_\n",
    "function can be used to quantize a Keras model for Akida. For this step in this example, an\n",
    "“8/8/8” quantization scheme will be applied to the floating point Keras model to produce 8-bit\n",
    "weights in the first layer, 8-bit weights in all other layers, and 8-bit activations.\n",
    "\n",
    "The quantization process results in a Keras model with custom [QuantizeML quantized layers](../../api_reference/quantizeml_apis.html#layers)_ substituted for the original Keras layers.\n",
    "All Keras API functions can be applied on this new model: ``summary()``, ``compile()``, ``fit()``. etc.\n",
    "\n",
    ".. Note:: The ``quantize`` function applies [several transformations](../../api_reference/quantizeml_apis.html#transforms)_ to\n",
    "          the original model. For example, it folds the batch normalization layers into the\n",
    "          corresponding neural layers. The new weights are computed according to this folding\n",
    "          operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jskupien/.local/lib/python3.10/site-packages/quantizeml/models/quantize.py:454: UserWarning: Quantizing per-axis with random calibration samples is not accurate.                       Set QuantizationParams.per_tensor_activations=True when calibrating with                        random samples.\n",
      "  warnings.warn(\"Quantizing per-axis with random calibration samples is not accurate.\\\n",
      "/home/jskupien/.local/lib/python3.10/site-packages/quantizeml/models/quantize.py:127: UserWarning: 'conv_pad_12' of type ZeroPadding2D is not supported to quantize, a Dequantizer is added before it and quantization will stop at this layer.\n",
      "  warnings.warn(f\"'{layer['config']['name']}' of type {layer['class_name']} \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquantizeml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantize, QuantizationParams\n\u001b[1;32m      3\u001b[0m qparams \u001b[38;5;241m=\u001b[39m QuantizationParams(input_weight_bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, weight_bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, activation_bits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model_quantized \u001b[38;5;241m=\u001b[39m \u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_keras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model_quantized\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/quantizeml/models/quantize.py:458\u001b[0m, in \u001b[0;36mquantize\u001b[0;34m(model, q_config, qparams, samples, num_samples, batch_size, epochs, quantize_until)\u001b[0m\n\u001b[1;32m    454\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuantizing per-axis with random calibration samples is not accurate.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124m                   Set QuantizationParams.per_tensor_activations=True when calibrating with \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124m                   random samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(model) \u001b[38;5;241m!=\u001b[39m ModelProto:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquantize_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mq_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mqparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mquantize_until\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantize_until\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m q_config:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported parameter q_config for ONNX models quantization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/quantizeml/models/quantize.py:395\u001b[0m, in \u001b[0;36mquantize_keras\u001b[0;34m(model, q_config, qparams, samples, num_samples, batch_size, epochs, quantize_until)\u001b[0m\n\u001b[1;32m    390\u001b[0m is_full_quantized \u001b[38;5;241m=\u001b[39m _handle_not_quantizable_layers(model,\n\u001b[1;32m    391\u001b[0m                                                    qmodel_config,\n\u001b[1;32m    392\u001b[0m                                                    skip_warning\u001b[38;5;241m=\u001b[39mquantize_until \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Build the model and transfer weights\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m qmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqmodel_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m apply_weights_to_model(qmodel, {var\u001b[38;5;241m.\u001b[39mname: var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mvariables}, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# Convert model into a functional one.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# Note if model was completely quantized, we add a last dequantizer to produce a float output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3330\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3322\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3324\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3326\u001b[0m )\n\u001b[1;32m   3327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3328\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3329\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3330\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3333\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3334\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3335\u001b[0m     )\n\u001b[1;32m   3336\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/functional.py:1505\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1504\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1506\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/functional.py:1445\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1441\u001b[0m ):\n\u001b[1;32m   1442\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1443\u001b[0m         input_tensors\n\u001b[1;32m   1444\u001b[0m     )\n\u001b[0;32m-> 1445\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1448\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1449\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1450\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1063\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# on symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list\n\u001b[1;32m   1062\u001b[0m ):\n\u001b[0;32m-> 1063\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_list\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:2593\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   2587\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   2588\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value\n\u001b[1;32m   2589\u001b[0m ):\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input\u001b[39;00m\n\u001b[1;32m   2591\u001b[0m     \u001b[38;5;66;03m# shape.\u001b[39;00m\n\u001b[1;32m   2592\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2593\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2594\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   2595\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2597\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictWrapper\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:2439\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   2436\u001b[0m         keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature\n\u001b[1;32m   2437\u001b[0m     )\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\n\u001b[1;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:2498\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m   2496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   2497\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m-> 2498\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2500\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mask_metadata(\n\u001b[1;32m   2502\u001b[0m     inputs, outputs, input_masks, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2503\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileetrhqsi8.py:133\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__check_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    132\u001b[0m shift \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuantizedBufferTempConv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuantizedDepthwiseBufferTempConv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_6\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself.input_shift\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1217\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1215\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m   \u001b[43m_py_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1270\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m body() \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;28;01melse\u001b[39;00m \u001b[43morelse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileetrhqsi8.py:128\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__check_inputs.<locals>.else_body_6\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileacpx64cl.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__decorator\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state\u001b[39m():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (outputs,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezv0g78p3.py:67\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     66\u001b[0m max_value \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_value\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1217\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1215\u001b[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1217\u001b[0m   \u001b[43m_py_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1270\u001b[0m, in \u001b[0;36m_py_if_stmt\u001b[0;34m(cond, body, orelse)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_py_if_stmt\u001b[39m(cond, body, orelse):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m body() \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;28;01melse\u001b[39;00m \u001b[43morelse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezv0g78p3.py:59\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_1\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21melse_body_1\u001b[39m():\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m do_return, retval_\n\u001b[0;32m---> 59\u001b[0m     max_value \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_value_quantizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileus2vnsuu.py:78\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, other)\u001b[0m\n\u001b[1;32m     76\u001b[0m frac_bits \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mminimum, (ag__\u001b[38;5;241m.\u001b[39mld(frac_bits), ag__\u001b[38;5;241m.\u001b[39mld(other_frac_bits)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     77\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(QFloat)\u001b[38;5;241m.\u001b[39mquantize, (ag__\u001b[38;5;241m.\u001b[39mld(inputs), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mvalue_bits, ag__\u001b[38;5;241m.\u001b[39mld(other)\u001b[38;5;241m.\u001b[39mscales, ag__\u001b[38;5;241m.\u001b[39mld(frac_bits)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 78\u001b[0m (outputs, shift) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_frac_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_value_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mqweights, (ag__\u001b[38;5;241m.\u001b[39mld(outputs),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     80\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mshift, (ag__\u001b[38;5;241m.\u001b[39mld(shift),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filevzdpb7ke.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__upscale\u001b[0;34m(self, frac_bits, value_bits)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     36\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(value_bits) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_bits\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m (fp, shift) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileur2i67ft.py:25\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__upscale\u001b[0;34m(self, frac_bits, value_bits)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrac_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_bits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:441\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m   _attach_error_metadata(e, converted_f)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileibmk9dhv.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__rescale\u001b[0;34m(self, frac_bits, value_bits)\u001b[0m\n\u001b[1;32m     52\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(assert_less), (ag__\u001b[38;5;241m.\u001b[39mld(shift), ag__\u001b[38;5;241m.\u001b[39mld(value_bits), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot rescale \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(frac_bits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fractional bits as it will saturate its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mag__\u001b[38;5;241m.\u001b[39mld(value_bits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m buffer\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     53\u001b[0m values \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mmultiply, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues, ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(pow2), (ag__\u001b[38;5;241m.\u001b[39mld(shift),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)), \u001b[38;5;28mdict\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrescale\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope)\n\u001b[0;32m---> 54\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloor_through\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/custom_gradient.py:343\u001b[0m, in \u001b[0;36mBind.__call__\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/custom_gradient.py:299\u001b[0m, in \u001b[0;36mcustom_gradient.<locals>.decorated\u001b[0;34m(wrapped, args, kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _eager_mode_decorator(wrapped, args, kwargs)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_graph_mode_decorator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/custom_gradient.py:523\u001b[0m, in \u001b[0;36m_graph_mode_decorator\u001b[0;34m(f, args, kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m original_tensors \u001b[38;5;241m=\u001b[39m all_tensors\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mgradient_override_map({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentityN\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}):\n\u001b[0;32m--> 523\u001b[0m   all_tensors \u001b[38;5;241m=\u001b[39m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity_n\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m original_tensors \u001b[38;5;241m=\u001b[39m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m original_tensors]\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:4287\u001b[0m, in \u001b[0;36midentity_n\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4285\u001b[0m \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m   4286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4287\u001b[0m   _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4288\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentityN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4289\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   4290\u001b[0m   _result \u001b[38;5;241m=\u001b[39m _dispatch\u001b[38;5;241m.\u001b[39mdispatch(\n\u001b[1;32m   4291\u001b[0m         identity_n, (), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   4292\u001b[0m       )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    792\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    794\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    795\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 2652\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_node_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2657\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2662\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[1;32m   2663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1026\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extract_traceback:\n\u001b[1;32m   1025\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetOpStackTrace(\n\u001b[0;32m-> 1026\u001b[0m       c_op, \u001b[43mtf_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1027\u001b[0m   )\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/tf_stack.py:162\u001b[0m, in \u001b[0;36mextract_stack\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"An eager-friendly alternative to traceback.extract_stack.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m  line, meant to masquerade as traceback.FrameSummary objects.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m thread_key \u001b[38;5;241m=\u001b[39m _get_thread_key()\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_stack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_source_mapper_stacks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthread_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_source_filter_stacks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mthread_key\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from quantizeml.models import quantize, QuantizationParams\n",
    "\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=8, activation_bits=8)\n",
    "model_quantized = quantize(model_keras, qparams=qparams)\n",
    "model_quantized.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. Note:: Note that the number of parameters for the floating and quantized models differs,\n",
    "          a consequence of the BatchNormalization folding and the additional parameters\n",
    "          added for quantization. For further details, please refer to their respective summary.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the quantized model accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_quantized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mevaluate(x_train, y_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy after 8-bit quantization:\u001b[39m\u001b[38;5;124m'\u001b[39m, compile_evaluate(\u001b[43mmodel_quantized\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_quantized' is not defined"
     ]
    }
   ],
   "source": [
    "def compile_evaluate(model):\n",
    "    \"\"\" Compiles and evaluates the model, then return accuracy score. \"\"\"\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model.evaluate(x_train, y_train, verbose=0)[1]\n",
    "\n",
    "\n",
    "print('Test accuracy after 8-bit quantization:', compile_evaluate(model_quantized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Effect of calibration\n",
    "\n",
    "The previous call to ``quantize`` was made with random samples for calibration\n",
    "(default parameters). While the observed drop in accuracy is minimal, that is\n",
    "around 1%, it can be worse on more complex models. Therefore, it is advised to\n",
    "use a set of real samples from the training set for calibration during a call\n",
    "to ``quantize``.\n",
    "Note that this remains a calibration step rather than a training step in that\n",
    "no output labels are required. Furthermore, any relevant data could be used for\n",
    "calibration. The recommended settings for calibration that are widely used to\n",
    "obtain the [zoo performance](../../model_zoo_performance.html#akida-2-0-models)_ are:\n",
    "\n",
    "- 1024 samples\n",
    "- a batch size of 100\n",
    "- 2 epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jskupien/.local/lib/python3.10/site-packages/quantizeml/models/quantize.py:127: UserWarning: 'conv_pad_12' of type ZeroPadding2D is not supported to quantize, a Dequantizer is added before it and quantization will stop at this layer.\n",
      "  warnings.warn(f\"'{layer['config']['name']}' of type {layer['class_name']} \"\n",
      "2024-11-12 18:51:39.675035: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 184320000 exceeds 10% of free system memory.\n",
      "2024-11-12 18:51:39.756981: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 184320000 exceeds 10% of free system memory.\n",
      "2024-11-12 18:51:39.757095: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 184320000 exceeds 10% of free system memory.\n",
      "2024-11-12 18:51:39.949198: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 368640000 exceeds 10% of free system memory.\n",
      "2024-11-12 18:51:39.950115: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 184320000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/11 [====>.........................] - ETA: 3s WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 11.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "11/11 [==============================] - 5s 46ms/step\n",
      " 2/11 [====>.........................] - ETA: 3s WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 11.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "11/11 [==============================] - 3s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "model_quantized = quantize(model_keras, qparams=qparams,\n",
    "                           samples=x_train, num_samples=1024, batch_size=100, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy for the quantized and calibrated model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after calibration: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy after calibration:', compile_evaluate(model_quantized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrating with real samples on this model recovers the initial float accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 4-bit quantization\n",
    "\n",
    "The accuracy of the 8/8/8 quantized model is equal to that of the Keras floating point\n",
    "model. In some cases, a smaller memory size for the model is required. This can be\n",
    "accomplished through quantization of the model to smaller bitwidths.\n",
    "\n",
    "The model will now be quantized to 8/4/4, that is 8-bit weights in the first layer with\n",
    "4-bit weights and activations in all other layers. Such a quantization scheme will usually\n",
    "introduce a performance drop.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/103 [..............................] - ETA: 32sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 103.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "103/103 [==============================] - 3s 7ms/step\n",
      "  3/103 [..............................] - ETA: 24sWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 103.0 batches). You may need to use the repeat() function when building your dataset.\n",
      "103/103 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=4, activation_bits=4)\n",
    "model_quantized = quantize(model_keras, qparams=qparams,\n",
    "                           samples=x_train, num_samples=1024, batch_size=10, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the 4-bit quantized accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy after 4-bit quantization: 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy after 4-bit quantization:', compile_evaluate(model_quantized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Model fine tuning (Quantization Aware Training)\n",
    "\n",
    "When a model suffers from an accuracy drop after quantization, fine tuning or Quantization\n",
    "Aware Training (QAT) may recover some or all of the original performance.\n",
    "\n",
    "Note that since this is a fine tuning step, both the number of epochs and learning rate are\n",
    "expected to be lower than during the initial float training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 9\n  y sizes: 7\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model_quantized\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m#TODO: define the loss function\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m),\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel_quantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 9\n  y sizes: 7\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model_quantized.compile(\n",
    "    loss=None, #TODO: define the loss function\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_quantized.fit(x_train, y_train, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model_quantized.evaluate(x_train, y_train, verbose=0)[1]\n",
    "print('Test accuracy after fine tuning:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Convert to Akida model\n",
    "\n",
    "When the quantized model produces satisfactory performance, it can be converted to the native\n",
    "Akida format. The [convert](../../api_reference/cnn2snn_apis.html#cnn2snn.convert)_ function\n",
    "returns a model in Akida format ready for inference.\n",
    "\n",
    "As with Keras, the summary() method provides a textual representation of the Akida model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "model_akida = convert(model_quantized)\n",
    "model_akida.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Check performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy = model_akida.evaluate(x_train, y_train)\n",
    "print('Test accuracy after conversion:', accuracy)\n",
    "\n",
    "# For non-regression purposes\n",
    "assert accuracy > 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Show predictions for a single image\n",
    "\n",
    "Display one of the test images, such as the first image in the dataset from above, to visualize\n",
    "the output of the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test a single example\n",
    "sample_image = 0\n",
    "image = x_train[sample_image]\n",
    "outputs = model_akida.predict(image.reshape(1, 28, 28, 1))\n",
    "print('Input Label: %i' % y_train[sample_image])\n",
    "\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "#TODO: adjust the following line to display the image\n",
    "# axarr[0].imshow(x_test[sample_image].reshape((28, 28)), cmap=cm.Greys_r)\n",
    "axarr[0].set_title('Class %d' % y_train[sample_image])\n",
    "axarr[1].bar(range(10), outputs.squeeze())\n",
    "axarr[1].set_xticks(range(10))\n",
    "plt.show()\n",
    "\n",
    "print(outputs.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the output from the model above. As is typical in backprop-trained models, the final\n",
    "layer is a Dense layer with one neuron for each of the 10 classes in the dataset. The goal of\n",
    "training is to maximize the response of the neuron corresponding to the label of each training\n",
    "sample while minimizing the responses of the other neurons.\n",
    "\n",
    "In the bar chart above, you can see the outputs from all 10 neurons. It is easy to see that neuron\n",
    "7 responds much more strongly than the others. The first sample is indeed a number 7.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
